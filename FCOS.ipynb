{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the Fully Connected One Stage (FCOS) object detection algorithm with training/eval on the PASCAL VOC 2007 dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the data has been downloaded (http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar) and extracted. The 'JPEGImages' subdirectory contains all the raw jpeg images. The 'Annotations' subdirectory contains corresponding XML files with object detection labels/metadata. The 'ImageSets/Main' subdirectory contains .txt files 'train.txt', 'val.txt' which contain identifiers of images for training and validation splits respectively. (There are also additional .txt files containing identifiers for images per class for each split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train images: 2501\n",
      "Num val images: 2510\n"
     ]
    }
   ],
   "source": [
    "# first lets read in the image identifiers for train-val splits\n",
    "with open(os.path.join('VOC2007_trainval', 'ImageSets', 'Main', 'train.txt')) as file:\n",
    "    identifiers_train = [line.strip() for line in file.readlines()]\n",
    "\n",
    "with open(os.path.join('VOC2007_trainval', 'ImageSets', 'Main', 'val.txt')) as file:\n",
    "    identifiers_val = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# now get the jpeg filepaths for the images\n",
    "image_filepaths_train = [os.path.join('VOC2007_trainval','JPEGImages',x+'.jpg') for x in identifiers_train]    \n",
    "image_filepaths_val = [os.path.join('VOC2007_trainval','JPEGImages',x+'.jpg') for x in identifiers_val]    \n",
    "\n",
    "# get the xml filepaths to object detection target labels\n",
    "target_filepaths_train = [os.path.join('VOC2007_trainval','Annotations',x+'.xml') for x in identifiers_train]    \n",
    "target_filepaths_val = [os.path.join('VOC2007_trainval','Annotations',x+'.xml') for x in identifiers_val]    \n",
    "\n",
    "print(f\"Num train images: {len(image_filepaths_train)}\")\n",
    "print(f\"Num val images: {len(image_filepaths_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set up a pytorch Dataset object for accessing image-target pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VOC2007_trainval/Annotations/000012.xml',\n",
       " 'VOC2007_trainval/Annotations/000017.xml',\n",
       " 'VOC2007_trainval/Annotations/000023.xml',\n",
       " 'VOC2007_trainval/Annotations/000026.xml',\n",
       " 'VOC2007_trainval/Annotations/000032.xml']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VOC2007(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_dir='VOC2007_trainval', split='train', image_size=224):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # first lets read in the image identifiers for train-val splits\n",
    "        with open(os.path.join(dataset_dir, 'ImageSets', 'Main', split+'.txt')) as file:\n",
    "            identifiers = [line.strip() for line in file.readlines()]\n",
    "        # now get the jpeg filepaths for the images\n",
    "        self.image_filepaths = [os.path.join(dataset_dir,'JPEGImages',x+'.jpg') for x in identifiers]    \n",
    "        # get the xml filepaths to object detection target labels\n",
    "        self.target_filepaths_train = [os.path.join(dataset_dir,'Annotations',x+'.xml') for x in identifiers]    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "\n",
    "    # fucntion for parsing XML file to get object detection target labels\n",
    "    def parse_xml(self, filepath):\n",
    "        # start at the root of the XML tree\n",
    "        root_node = ET.parse(filepath).getroot()\n",
    "        annotations = {}\n",
    "        # get image size\n",
    "        annotations['size'] = {\n",
    "            'width': root_node.find('size/width').text,\n",
    "            'height': root_node.find('size/height').text\n",
    "        }\n",
    "        # get all the object bounding boxes\n",
    "        objects = []\n",
    "        for obj in root_node.findall('object'):\n",
    "            # for each object, get class name, difficulty identifier (0: easy, 1: difficult) and bounding box (top-left and bottom-right corner) coordinates \n",
    "            object_dict = {\n",
    "                'class': obj.find('name').text,\n",
    "                'difficult': obj.find('difficult').text,\n",
    "                'bndbox': {\n",
    "                    'xmin': int(obj.find('bndbox/xmin').text),\n",
    "                    'ymin': int(obj.find('bndbox/xmin').text),\n",
    "                    'xmax': int(obj.find('bndbox/xmin').text),\n",
    "                    'ymax': int(obj.find('bndbox/xmin').text),\n",
    "                }\n",
    "            }\n",
    "            objects.append(object_dict)\n",
    "        annotations['objects'] = objects\n",
    "        return annotations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
